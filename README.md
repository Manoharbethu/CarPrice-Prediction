# ðŸš— Comparative Analysis of an Explainable Ensemble of Multi-View Deep Learning Models for Future Price Prediction of Pre-Owned Cars
This repository contains the implementation and analysis of a novel ensemble deep learning architecture designed for accurate and interpretable price prediction of pre-owned vehicles. <br/>
The core challenge addressed by this research is bridging the high accuracy of modern deep learning models with the critical need for transparency and trust in high-stakes financial decisions, such as those in the automotive market.
# ðŸŒŸ Key Features of the Approach
The proposed ensemble model integrates multiple deep learning models to analyze distinct "views" or facets of vehicle data, while prioritizing explainability through built-in interpretation mechanisms. <br/>
## 1. Multi-View Data Integration <br/>
The model synthesizes information from diverse data sources to capture nuanced patterns that single-view models might miss: <br/>
Structured Data (Tabular): Numerical and categorical features like mileage, vehicle age, brand, model, engine capacity, and historical price trends. <br/>
Textual Data (Descriptions): Information extracted from seller descriptions and expert opinions using NLP techniques. <br/>
Image Data (Visual): Visual information from vehicle images used to evaluate condition and aesthetic attributes. <br/>
## 2. Deep Learning Architectures 
The ensemble combines specialized models for each data view: <br/>
Convolutional Neural Networks (CNN): Used for Image Analysis to assess visual attributes like dents, scratches, and overall paint condition. <br/>
Recurrent Neural Networks (RNN) / Transformer Models: Employed for Text Analysis to extract features, condition descriptions, and seller sentiment from textual data. <br/>
Multi-Layer Perceptron (MLP): Utilized for Structured Data to learn complex relationships among numerical and categorical features. <br/>
Ensemble Model: The final prediction is generated by combining the outputs of the CNN, RNN/Transformer, and MLP using a weighted averaging mechanism. <br/>
## 3. Built-in Explainability
The integration of explainability techniques transforms the model into a transparent decision support system. <br/>


SHAP Values: Can reveal how much each feature (e.g., mileage, condition, brand reputation) contributes to the final predicted price, aiding user understanding of the model's reasoning.


Grad-CAM: Highlights the specific regions in an image that the CNN focuses on when assessing vehicle condition.
